{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqkuyoTH61IF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Callable, Optional, Sequence, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from monai.networks.nets import resnet\n",
        "\n",
        "try:\n",
        "    import torchio as tio\n",
        "except Exception:\n",
        "    tio = None\n",
        "\n",
        "def get_transform_torchio():\n",
        "    if tio is None:\n",
        "        print(\"[TorchIO] Not installed; training will run without augmentation.\")\n",
        "        return None\n",
        "\n",
        "    aug = tio.Compose([\n",
        "        # Rotation affine (±10°), no scaling or translation\n",
        "        tio.RandomAffine(scales=1.0, degrees=10, translation=0),\n",
        "        # Flips along AP & SI (0.5 probability each)\n",
        "        tio.RandomFlip(axes=('AP', 'SI'), flip_probability=0.5),\n",
        "        # Mild intensity gamma jitter (±10% in log space)\n",
        "        tio.RandomGamma(log_gamma=(-0.1, 0.1)),\n",
        "    ])\n",
        "\n",
        "    def apply(x: Union[np.ndarray, torch.Tensor]) -> torch.Tensor:\n",
        "        # x: [C, D, H, W], float32\n",
        "        if isinstance(x, np.ndarray):\n",
        "            x = torch.from_numpy(x.astype(np.float32))\n",
        "        subj = tio.Subject(img=tio.ScalarImage(tensor=x))\n",
        "        out = aug(subj)\n",
        "        return out['img'].tensor  # [C, D, H, W], float32\n",
        "    return apply\n",
        "\n",
        "class Cfg:\n",
        "    seed = 42\n",
        "    n_splits = 5\n",
        "    max_epochs = 1000\n",
        "    patience = 50\n",
        "    batch_size = 3\n",
        "    num_workers = 16\n",
        "\n",
        "    # optimization\n",
        "    weight_decay = 1e-4\n",
        "    lr_encoders = 1e-4\n",
        "    lr_mlps     = 1e-3\n",
        "    lr_decoders = 3e-3\n",
        "    wd_decoders = 0.0    # often better w/ 0 WD on decoders\n",
        "    warmup_freeze_epochs = 0  # set >0 to freeze encoders at start\n",
        "\n",
        "    # IO\n",
        "    save_root = Path(\"runs/ae_sep_160x160x48\")\n",
        "\n",
        "    # data shape & preprocessing\n",
        "    target_shape = (160, 160, 48)  # (D, H, W)\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "set_seed(Cfg.seed)\n",
        "\n",
        "\n",
        "# -------------------------------- Dataset ------------------------------------\n",
        "class MyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Flexible dataset:\n",
        "      - ids: sequence of case IDs OR tuples of (tumor_path, liver_path)\n",
        "      - get_paths: optional callable mapping id -> (tumor_path, liver_path)\n",
        "      - transform: TorchIO callable that operates on [C, D, H, W]\n",
        "    Returns:\n",
        "      x: torch.float32 [2, 160, 160, 48]\n",
        "      case_id: identifier/path tuple\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        ids: Sequence,\n",
        "        transform: Optional[Callable] = None,\n",
        "        get_paths: Optional[Callable[[object], Tuple[str, str]]] = None,\n",
        "        target_shape: Tuple[int, int, int] = Cfg.target_shape,\n",
        "    ):\n",
        "        self.ids = list(ids)\n",
        "        self.transform = transform\n",
        "        self.get_paths = get_paths\n",
        "        self.target_shape = target_shape\n",
        "\n",
        "    def __len__(self): return len(self.ids)\n",
        "\n",
        "    def _resolve_paths(self, case_id) -> Tuple[str, str]:\n",
        "        # If ID is already a tuple of paths, use it directly\n",
        "        if isinstance(case_id, (tuple, list)) and len(case_id) == 2:\n",
        "            return case_id[0], case_id[1]\n",
        "        # If ID is a dict-like with explicit keys\n",
        "        if isinstance(case_id, dict):\n",
        "            return case_id[\"tumor_path\"], case_id[\"liver_path\"]\n",
        "        # Otherwise, require a resolver callable\n",
        "        if self.get_paths is None:\n",
        "            raise ValueError(\n",
        "                \"MyDataset needs 'get_paths' to resolve case_id -> (tumor_path, liver_path)\"\n",
        "            )\n",
        "        return self.get_paths(case_id)\n",
        "\n",
        "    @staticmethod\n",
        "    def _load_volume(path: str) -> np.ndarray:\n",
        "        # Supports .npy or NIfTI (.nii/.nii.gz)\n",
        "        if path.endswith(\".npy\"):\n",
        "            vol = np.load(path).astype(np.float32)\n",
        "        else:\n",
        "            import nibabel as nib\n",
        "            vol = nib.load(path).get_fdata().astype(np.float32)\n",
        "        # If 4D, take first channel\n",
        "        if vol.ndim == 4:\n",
        "            vol = vol[..., 0]\n",
        "        # Try to coerce to (D,H,W): if the first axis looks like H/W, swap\n",
        "        D, H, W = vol.shape if vol.ndim == 3 else (0, 0, 0)\n",
        "        # Heuristic: if last dim is small (like 48) it's probably W, so keep\n",
        "        return vol\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        case_id = self.ids[idx]\n",
        "        tumor_path, liver_path = self._resolve_paths(case_id)\n",
        "        t = self._load_volume(tumor_path)\n",
        "        l = self._load_volume(liver_path)\n",
        "\n",
        "        # Stack to channels-first [C,D,H,W]\n",
        "        x = np.stack([t, l], axis=0).astype(np.float32)\n",
        "\n",
        "        # TorchIO aug (train only)\n",
        "        if self.transform is not None:\n",
        "            x = self.transform(x)  # expects/returns [C,D,H,W]\n",
        "            if not isinstance(x, torch.Tensor):\n",
        "                x = torch.from_numpy(np.asarray(x, dtype=np.float32))\n",
        "        else:\n",
        "            x = torch.from_numpy(x)\n",
        "\n",
        "        return x, case_id\n",
        "\n",
        "\n",
        "# ---------------------------- Model Components --------------------------------\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"2048 -> 1024 -> 256 latent.\"\"\"\n",
        "    def __init__(self, input_dim: int = 2048, latent_dim: int = 256, dropout: float = 0.0):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(1024, latent_dim),\n",
        "        )\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.proj(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    256 latent -> [1, 160, 160, 48]\n",
        "    Base seed: (10,10,3) -> 4 × ConvTranspose3d (stride=2) -> (160,160,48)\n",
        "    Linear output (Option A).\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim: int = 256, base_shape=(10, 10, 3)):\n",
        "        super().__init__()\n",
        "        self.base_shape = base_shape\n",
        "        C0 = 128\n",
        "        self.fc = nn.Linear(latent_dim, C0 * np.prod(self.base_shape))\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(C0, 64, kernel_size=2, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.up3 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(32, 16, kernel_size=2, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.up4 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(16, 8, kernel_size=2, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(8, 8, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.out = nn.Conv3d(8, 1, kernel_size=3, padding=1)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv3d, nn.ConvTranspose3d, nn.Linear)):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
        "                if getattr(m, \"bias\", None) is not None:\n",
        "                    nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        B = z.size(0)\n",
        "        x = self.fc(z).view(B, 128, *self.base_shape)  # [B,128,10,10,3]\n",
        "        x = self.up1(x)\n",
        "        x = self.up2(x)\n",
        "        x = self.up3(x)\n",
        "        x = self.up4(x)        # [B,8,160,160,48]\n",
        "        x = self.out(x)        # [B,1,160,160,48] (linear)\n",
        "        return x\n",
        "\n",
        "def build_encoder() -> nn.Module:\n",
        "    \"\"\"Single-channel 3D ResNet-50-like encoder that returns a 2048-D vector.\"\"\"\n",
        "    return resnet.resnet50(\n",
        "        n_input_channels=1,\n",
        "        feed_forward=False,\n",
        "        shortcut_type=\"B\",\n",
        "        bias_downsample=False,\n",
        "        pretrained=True,\n",
        "    )\n",
        "\n",
        "\n",
        "# --------------------------------- Loss --------------------------------------\n",
        "def recon_loss(pred: torch.Tensor, target: torch.Tensor,\n",
        "               l1_w: float = 1.0, mse_w: float = 1.0):\n",
        "    # Option A: z-score domain — no BCE\n",
        "    loss = 0.0\n",
        "    if l1_w:  loss += l1_w  * F.l1_loss(pred, target, reduction=\"mean\")\n",
        "    if mse_w: loss += mse_w * F.mse_loss(pred, target, reduction=\"mean\")\n",
        "    return loss\n",
        "\n",
        "\n",
        "# --------------------------- Optimizer grouping -------------------------------\n",
        "def add_groups(module: nn.Module, lr: float, wd: float):\n",
        "    decays, nodecays = [], []\n",
        "    for n, p in module.named_parameters():\n",
        "        if not p.requires_grad: continue\n",
        "        if any(k in n.lower() for k in (\"bias\", \"bn\", \"norm\", \"ln\", \"gn\")):\n",
        "            nodecays.append(p)  # no weight decay for norms/bias\n",
        "        else:\n",
        "            decays.append(p)\n",
        "    groups = []\n",
        "    if decays:   groups.append({\"params\": decays,   \"lr\": lr, \"weight_decay\": wd})\n",
        "    if nodecays: groups.append({\"params\": nodecays, \"lr\": lr, \"weight_decay\": 0.0})\n",
        "    return groups\n",
        "\n",
        "\n",
        "# ------------------------------- Train / Eval --------------------------------\n",
        "def train_one_epoch(\n",
        "    enc_tumor, enc_liver,\n",
        "    mlp_tumor, mlp_liver,\n",
        "    dec_tumor, dec_liver,\n",
        "    loader, optimizer,\n",
        "    epoch: int\n",
        "):\n",
        "    # optional warmup freeze for encoders\n",
        "    warm = Cfg.warmup_freeze_epochs\n",
        "    freeze = (epoch <= warm and warm > 0)\n",
        "    for p in enc_tumor.parameters(): p.requires_grad = not freeze\n",
        "    for p in enc_liver.parameters(): p.requires_grad = not freeze\n",
        "\n",
        "    enc_tumor.train(); enc_liver.train()\n",
        "    mlp_tumor.train(); mlp_liver.train()\n",
        "    dec_tumor.train(); dec_liver.train()\n",
        "\n",
        "    running, n = 0.0, 0\n",
        "    for images, _ in loader:\n",
        "        images = images.to(device)           # [B, 2, 160, 160, 48]\n",
        "        tumor = images[:, 0:1, ...]\n",
        "        liver = images[:, 1:2, ...]\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Tumor branch\n",
        "        f_t = enc_tumor(tumor)               # [B,2048]\n",
        "        z_t = mlp_tumor(f_t)                 # [B,256]\n",
        "        r_t = dec_tumor(z_t)                 # [B,1,160,160,48]\n",
        "\n",
        "        # Liver branch\n",
        "        f_l = enc_liver(liver)\n",
        "        z_l = mlp_liver(f_l)\n",
        "        r_l = dec_liver(z_l)\n",
        "\n",
        "        loss = recon_loss(r_t, tumor) + recon_loss(r_l, liver)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bs = images.size(0)\n",
        "        running += loss.item() * bs\n",
        "        n += bs\n",
        "\n",
        "    return running / max(1, n)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(\n",
        "    enc_tumor, enc_liver,\n",
        "    mlp_tumor, mlp_liver,\n",
        "    dec_tumor, dec_liver,\n",
        "    loader\n",
        "):\n",
        "    enc_tumor.eval(); enc_liver.eval()\n",
        "    mlp_tumor.eval(); mlp_liver.eval()\n",
        "    dec_tumor.eval(); dec_liver.eval()\n",
        "\n",
        "    running, n = 0.0, 0\n",
        "    last_batch = None\n",
        "    for images, _, _ in loader:\n",
        "        images = images.to(device)\n",
        "        tumor = images[:, 0:1, ...]\n",
        "        liver = images[:, 1:2, ...]\n",
        "\n",
        "        f_t = enc_tumor(tumor); z_t = mlp_tumor(f_t); r_t = dec_tumor(z_t)\n",
        "        f_l = enc_liver(liver); z_l = mlp_liver(f_l); r_l = dec_liver(z_l)\n",
        "\n",
        "        loss = recon_loss(r_t, tumor) + recon_loss(r_l, liver)\n",
        "\n",
        "        bs = images.size(0)\n",
        "        running += loss.item() * bs\n",
        "        n += bs\n",
        "        last_batch = (tumor.detach().cpu(), r_t.detach().cpu(),\n",
        "                      liver.detach().cpu(), r_l.detach().cpu())\n",
        "    return running / max(1, n), last_batch\n",
        "\n",
        "\n",
        "# --------------------------------- Driver ------------------------------------\n",
        "def run_training(\n",
        "    ids: Sequence,\n",
        "    transform_torchio: Optional[Callable] = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    ids: sequence of IDs you want to train on. Each item can be:\n",
        "         - a tuple (tumor_path, liver_path)\n",
        "    \"\"\"\n",
        "    Cfg.save_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    kf = KFold(n_splits=Cfg.n_splits, shuffle=True, random_state=Cfg.seed)\n",
        "    idx_array = np.arange(len(ids))\n",
        "\n",
        "    for fold_idx, (idx_train_val, idx_test) in enumerate(kf.split(idx_array), start=0):\n",
        "        idx_train = idx_train_val[:-1]\n",
        "        idx_val   = idx_train_val[-1:]\n",
        "\n",
        "        # Datasets\n",
        "        train_set = MyDataset([ids[i] for i in idx_train], transform_torchio, get_paths)\n",
        "        val_set   = MyDataset([ids[i] for i in idx_val],   None,               get_paths)\n",
        "        test_set  = MyDataset([ids[i] for i in idx_test],  None,               get_paths)\n",
        "\n",
        "        # Persist split indices\n",
        "        fold_dir = Cfg.save_root / f\"fold_{fold_idx:02d}\"\n",
        "        fold_dir.mkdir(parents=True, exist_ok=True)\n",
        "        np.save(fold_dir / \"idx_train.npy\", idx_train)\n",
        "        np.save(fold_dir / \"idx_val.npy\", idx_val)\n",
        "        np.save(fold_dir / \"idx_test.npy\", idx_test)\n",
        "\n",
        "        # Loaders\n",
        "        train_loader = DataLoader(train_set, batch_size=Cfg.batch_size, shuffle=True,\n",
        "                                  num_workers=Cfg.num_workers, drop_last=True)\n",
        "        val_loader   = DataLoader(val_set,   batch_size=len(val_set), shuffle=False)\n",
        "        test_loader  = DataLoader(test_set,  batch_size=len(test_set), shuffle=False)\n",
        "\n",
        "        # Build separate components\n",
        "        enc_tumor = build_encoder().to(device)\n",
        "        enc_liver = build_encoder().to(device)\n",
        "        mlp_tumor = MLP(input_dim=2048, latent_dim=256).to(device)\n",
        "        mlp_liver = MLP(input_dim=2048, latent_dim=256).to(device)\n",
        "        dec_tumor = Decoder(latent_dim=256).to(device)\n",
        "        dec_liver = Decoder(latent_dim=256).to(device)\n",
        "\n",
        "        # Optimizer with explicit groups (encoders vs mlps vs decoders)\n",
        "        param_groups = []\n",
        "        param_groups += add_groups(enc_tumor, lr=Cfg.lr_encoders, wd=Cfg.weight_decay)\n",
        "        param_groups += add_groups(enc_liver, lr=Cfg.lr_encoders, wd=Cfg.weight_decay)\n",
        "        param_groups += add_groups(mlp_tumor, lr=Cfg.lr_mlps,     wd=Cfg.weight_decay)\n",
        "        param_groups += add_groups(mlp_liver, lr=Cfg.lr_mlps,     wd=Cfg.weight_decay)\n",
        "        param_groups += add_groups(dec_tumor, lr=Cfg.lr_decoders, wd=Cfg.wd_decoders)\n",
        "        param_groups += add_groups(dec_liver, lr=Cfg.lr_decoders, wd=Cfg.wd_decoders)\n",
        "\n",
        "        # Safety: ensure no duplicate params across groups\n",
        "        all_params = [p for g in param_groups for p in g[\"params\"]]\n",
        "        assert len(all_params) == len(set(map(id, all_params))), \"Duplicate params across groups!\"\n",
        "\n",
        "        optimizer = torch.optim.Adam(param_groups)\n",
        "\n",
        "        best_val, no_improve = float(\"inf\"), 0\n",
        "        ckpt = {\n",
        "            \"enc_tumor\": fold_dir / \"enc_tumor_best.pth\",\n",
        "            \"enc_liver\": fold_dir / \"enc_liver_best.pth\",\n",
        "            \"mlp_tumor\": fold_dir / \"mlp_tumor_best.pth\",\n",
        "            \"mlp_liver\": fold_dir / \"mlp_liver_best.pth\",\n",
        "            \"dec_tumor\": fold_dir / \"dec_tumor_best.pth\",\n",
        "            \"dec_liver\": fold_dir / \"dec_liver_best.pth\",\n",
        "        }\n",
        "\n",
        "        for epoch in range(1, Cfg.max_epochs + 1):\n",
        "            tr = train_one_epoch(\n",
        "                enc_tumor, enc_liver, mlp_tumor, mlp_liver, dec_tumor, dec_liver,\n",
        "                train_loader, optimizer, epoch\n",
        "            )\n",
        "            va, last_batch = evaluate(\n",
        "                enc_tumor, enc_liver, mlp_tumor, mlp_liver, dec_tumor, dec_liver,\n",
        "                val_loader\n",
        "            )\n",
        "            print(f\"[Fold {fold_idx:02d}] Epoch {epoch:04d} | train {tr:.6f} | val {va:.6f}\")\n",
        "\n",
        "            if va < best_val - 1e-6:\n",
        "                best_val, no_improve = va, 0\n",
        "                torch.save(enc_tumor.state_dict(), ckpt[\"enc_tumor\"])\n",
        "                torch.save(enc_liver.state_dict(), ckpt[\"enc_liver\"])\n",
        "                torch.save(mlp_tumor.state_dict(), ckpt[\"mlp_tumor\"])\n",
        "                torch.save(mlp_liver.state_dict(), ckpt[\"mlp_liver\"])\n",
        "                torch.save(dec_tumor.state_dict(), ckpt[\"dec_tumor\"])\n",
        "                torch.save(dec_liver.state_dict(), ckpt[\"dec_liver\"])\n",
        "            else:\n",
        "                no_improve += 1\n",
        "                if no_improve >= Cfg.patience:\n",
        "                    print(f\"[Fold {fold_idx:02d}] Early stopping at epoch {epoch}, best val {best_val:.6f}\")\n",
        "                    break\n",
        "\n",
        "        # Test with best weights\n",
        "        if all(p.exists() for p in ckpt.values()):\n",
        "            enc_tumor.load_state_dict(torch.load(ckpt[\"enc_tumor\"], map_location=device))\n",
        "            enc_liver.load_state_dict(torch.load(ckpt[\"enc_liver\"], map_location=device))\n",
        "            mlp_tumor.load_state_dict(torch.load(ckpt[\"mlp_tumor\"], map_location=device))\n",
        "            mlp_liver.load_state_dict(torch.load(ckpt[\"mlp_liver\"], map_location=device))\n",
        "            dec_tumor.load_state_dict(torch.load(ckpt[\"dec_tumor\"], map_location=device))\n",
        "            dec_liver.load_state_dict(torch.load(ckpt[\"dec_liver\"], map_location=device))\n",
        "\n",
        "        te, _ = evaluate(\n",
        "            enc_tumor, enc_liver, mlp_tumor, mlp_liver, dec_tumor, dec_liver, test_loader\n",
        "        )\n",
        "        print(f\"[Fold {fold_idx:02d}] TEST recon loss: {te:.6f}\")\n",
        "\n",
        "\n",
        "# --------------------------------- Usage -------------------------------------\n",
        "transform_torchio = get_transform_torchio()\n",
        "\n",
        "# Prepare your ID list. Easiest is to pass pairs of file paths:\n",
        "# ids = [\n",
        "#   (\"/path/to/tumor_case1.nii.gz\", \"/path/to/liver_case1.nii.gz\"),\n",
        "#   (\"/path/to/tumor_case2.nii.gz\", \"/path/to/liver_case2.nii.gz\"),\n",
        "#   ...\n",
        "# ]\n",
        "\n",
        "run_training(ids, transform_torchio=transform_torchio)\n"
      ]
    }
  ]
}